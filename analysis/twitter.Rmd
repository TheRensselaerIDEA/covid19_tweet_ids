---
title: "Twitter Notebook"
output: html_document
params:
  # snapshot mode can be 'save', 'load', and 'none'.
  # 'save': the notebook will retrieve data from elasticsearch and run the full processing pipeline,
  #         saving a snapshot containing the source data, cluster / subcluster assignments, summaries, 
  #         and t-sne projection coordinates. Snapshots are saved to the location specified in snapshots_path.
  # 'load': the notebook will load a saved snapshot and only execute the code to render visualizations.
  # 'none': the notebook will run as in 'save' mode, but will not output a snapshot.
  snapshot_mode:
    input: select
    choices: ["none", "save", "load"]
    value: "none"
  # file name (without extension) of the snapshot to save or load. This field must be provided in 'load' mode.
  # in save mode, this field may be provided or left blank. If provided, the snapshot will be saved
  # using the given name and overwrite it if it already exists. If blank, the snapshot will be saved
  # using a timestamp as the name.
  snapshot_name: ""
  # name of the directory in which snapshots are located.
  snapshot_path: "/data/COVID-Twitter/analysis/snapshots"
---

```{r setup, include=FALSE}
# Required R package installation:
# These will install packages if they are not already installed
# Set the correct default repository
r = getOption("repos")
r["CRAN"] = "http://cran.rstudio.com"
options(repos = r)

if (!require("knitr")) {
  install.packages("knitr")
  library(knitr)
}

if(!require('dplyr')) {
  install.packages("dplyr")
  library(dplyr)
}

if(!require('Rtsne')) {
  install.packages("Rtsne")
  library(Rtsne)
}

if (!require("kableExtra")) {
  install.packages("kableExtra")
  library(kableExtra)
}

knitr::opts_chunk$set(echo = TRUE)

unlockBinding("params", env = .GlobalEnv)

source("Elasticsearch.R")
source("Summarizer.R")
source("text_helpers.R")
source("plot_helpers.R")
```

```{r, echo=FALSE}
#Load snapshot if snapshot mode is 'load'
snapshot_loaded <- FALSE
params$snapshot_name <- ifelse(params$snapshot_name == "", 
                               paste("twitter_snapshot_", format(Sys.time(), "%Y%m%d%H%M%S"), sep=""), 
                               params$snapshot_name)
snapshot_filename <- file.path(params$snapshot_path, paste(params$snapshot_name, ".Rdata", sep=""))

if (params$snapshot_mode == "load") {
  load(snapshot_filename)
  #reset the snapshot mode to correct value after load
  params$snapshot_mode <- "load"
  snapshot_loaded <- TRUE
}
```

```{r, echo=FALSE}
if (!snapshot_loaded) {
  # Set server resource locations here:
  elasticsearch_index <- "coronavirus-data-masks"
  elasticsearch_host <- "lp01.idea.rpi.edu"
  elasticsearch_path <- "elasticsearch"
  elasticsearch_port <- 443
  elasticsearch_schema <- "https"
  
  summarizer_url <- "http://idea-node-05:8080/batchsummarize"
}
```

### Configure the search parameters here:

Note: large date ranges can take some time to process on initial search due to the sheer volume of data we have collected. Subsequent searches using the same date range should run quickly due to Elasticsearch caching.

`r if(snapshot_loaded) paste('<h4 style="color: red">Search parameters loaded from snapshot "', params$snapshot_name, '"</h4>', sep='')`

```{r echo=!snapshot_loaded}
if (!snapshot_loaded) {
  # query start date/time (inclusive)
  rangestart <- "2020-03-01 00:00:00"
  
  # query end date/time (exclusive)
  rangeend <- "2020-08-01 00:00:00"
  
  # text filter restricts results to only those containing words, phrases, or meeting a boolean condition. This query syntax is very flexible and supports a wide variety of filter scenarios:
  # words: text_filter <- "cdc nih who"  ...contains "cdc" or "nih" or "who"
  # phrase: text_filter <- '"vitamin c"' ...contains exact phrase "vitamin c"
  # boolean condition: <- '(cdc nih who) +"vitamin c"' ...contains ("cdc" or "nih" or "who") and exact phrase "vitamin c"
  #full specification here: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html
  text_filter <- ""
  
  # location filter acts like text filter except applied to the location of the tweet instead of its text body.
  location_filter <- ""
  
  # if FALSE, location filter considers both user-povided and geotagged locations. If TRUE, only geotagged locations are considered.
  must_have_geo <- FALSE
  
  # query semantic similarity phrase (choose one of these examples or enter your own)
  #semantic_phrase <- "Elementary school students are not coping well with distance learning."
  #semantic_phrase <- "I am diabetic and out of work because of coronavirus. I am worried I won't be able to get insulin without insurance."
  semantic_phrase <- ""
  
  # sentiment type (only 'vader' is supported for now)
  # if the requested sentiment type is not available for the current index or sample, the sentiment
  # column in the result set will contain NA values.
  sentiment_type <- "vader"
  
  # query lower bound for sentiment (inclusive). Enter a numeric value or for no lower bound set to NA.
  sentiment_lower <- NA
  
  # query upper bound for sentiment (inclusive). Enter a numeric value or for no upper bound set to NA.
  sentiment_upper <- NA
  
  # return results in chronological order or as a random sample within the range
  # (ignored if semantic_phrase is not blank)
  random_sample <- TRUE
  
  # number of results to return (to return all results, set to NA)
  resultsize <- 10000
  
  # minimum number of results to return. This should be set according to the needs of the analysis (i.e. enough samples for statistical significance)
  min_results <- 500
}
```

### Configure the hyperparameters here:

`r if(snapshot_loaded) paste('<h4 style="color: red">Hyperparameters loaded from snapshot "', params$snapshot_name, '"</h4>', sep='')`

```{r echo=!snapshot_loaded}
if (!snapshot_loaded) {
  #--------------------------
  # PSEUDORANDOM SEEDS
  #--------------------------
  # Optionally specify seeds for reproducibility. For no seed, set to NA on any of these settings.
  # seed for random sampling (if enabled)
  random_seed <- 100
  # seed for k-means
  kmeans_clusters_seed <- 300
  kmeans_subclusters_seed <- 500
  # seed for t-sne
  tsne_clusters_seed <- 700
  tsne_subclusters_seed <- 900
  
  #--------------------------
  # K-MEANS HYPERPARAMS
  #--------------------------
  # range of k choices to test for elbow and silhouette plots
  k_test_range <- 2:40
  
  # number of random starts
  kmeans_nstart <- 2
  
  # maximum iterations
  kmeans_max_iter <- 100
  
  # number of high level clusters (temporary until automatic selection implemented)
  k <- 15
  
  # number of subclusters per high level cluster (temporary until automatic selection implemented)
  cluster.k <- 15
  
  #--------------------------
  # LABELING HYPERPARAMS
  #--------------------------
  # Construct master label using top-k words across the entire sample
  master_label_top_k <- 8
  
  # Construct cluster labels using top-k words across each cluster
  cluster_label_top_k <- 3
  
  # Construct subcluster labels using top-k words across each subcluster
  subcluster_label_top_k <- 3
  
  #--------------------------
  # SUMMARIZATION HYPERPARAMS
  #--------------------------
  # number of nearest neighbors to the center to use for cluster & subcluster summarization
  summarize_center_nn <- 20
  
  # summarization model inference hyperparameters
  summarize_max_len <- 120
  summarize_num_beams <- 6
  summarize_temperature <- 1.0
  
  #--------------------------
  # T-SNE HYPERPARAMS
  #--------------------------
  # hyperparams for clusters
  tsne_clusters_perplexity <- 25
  tsne_clusters_max_iter <- 750
  
  # hyperparams for subclusters
  tsne_subclusters_perplexity <- 12
  tsne_subclusters_max_iter <- 500
}
```

### Configure the output settings here:

```{r}
# plot mode - '2d' or '3d'.
# Note: if loading a snapshot, changing the plot mode will trigger T-SNE to re-run.
plot_mode <- "2d"

# If TRUE, cluster and subcluster summaries will be generated using nearest neighbors to the center.
# Note: if loading a snapshot, disabling summarization will do nothing if it was previously enabled.
summarize_clusters <- FALSE

# If TRUE, run and output k-means elbow plots
# Note: if loading a snapshot, disabling elbow plots will do nothing if they were previously enabled.
compute_elbow <- FALSE
# If TRUE, run and output k-means silhouette plots
# Note: if loading a snapshot, disabling silhouette plots will do nothing if they were previously enabled.
compute_silhouette <- FALSE

# show/hide extra info (temporary until tabs are implemented)
show_original_subcluster_plots <- FALSE
show_regrouped_subcluster_plots <- TRUE
show_word_freqs <- FALSE
show_center_nn <- FALSE

# visualize sentiment and divisiveness
show_overall_sentiment_discrete <- TRUE
show_overall_sentiment_continuous <- TRUE
show_cluster_sentiment_continuous <- TRUE
show_cluster_sentiment_discrete <- TRUE
# threshold that represents the cutoff from neutral to positive above zero
# and neutral to negative below zero. Used to turn sentiment into a variable with discrete values
sentiment_threshold <- 0.05 # 0.05 recommended for VADER sentiment

```

```{r, echo=FALSE}
###############################################################################
# Get the tweets from Elasticsearch using the search parameters defined above
###############################################################################
if (!snapshot_loaded) {
  resultfields <- '"created_at", "user.screen_name", "user.verified", "user.location", "place.full_name", "place.country", "text", "full_text", "extended_tweet.full_text", "embedding.use_large.primary"'
  
  results <- do_search(indexname=elasticsearch_index, 
                       rangestart=rangestart,
                       rangeend=rangeend,
                       text_filter=text_filter,
                       location_filter=location_filter,
                       semantic_phrase=semantic_phrase,
                       must_have_embedding=TRUE,
                       must_have_geo=must_have_geo,
                       sentiment_type=sentiment_type,
                       sentiment_lower=sentiment_lower,
                       sentiment_upper=sentiment_upper,
                       random_sample=random_sample,
                       random_seed=random_seed,
                       resultsize=resultsize,
                       resultfields=resultfields,
                       elasticsearch_host=elasticsearch_host,
                       elasticsearch_path=elasticsearch_path,
                       elasticsearch_port=elasticsearch_port,
                       elasticsearch_schema=elasticsearch_schema)
  
  # this dataframe must contains the tweet text and other metadata.
  # validate that all necessary fields exist in the queried index and were returned:
  required_fields <- c("full_text", "created_at", "user_screen_name", "user_verified", "user_location", "place.country", "place.full_name", "sentiment")
  validate_results(results$df, min_results, required_fields)
  
  tweet.vectors.df <- results$df[,required_fields]
  
  # this matrix contains the embedding vectors for every tweet in tweet.vectors.df
  tweet.vectors.matrix <- t(simplify2array(results$df[,"embedding.use_large.primary"]))
}
```

```{r, echo=FALSE}
###############################################################################
# Clean the tweet and user location text, and set up tweet.vectors.df 
# the way we want it by consolidating the location field and computing
# location type
###############################################################################
if (!snapshot_loaded) {
  tweet.vectors.df$user_location <- ifelse(is.na(tweet.vectors.df$place.full_name), 
                                           tweet.vectors.df$user_location, 
                                           paste(tweet.vectors.df$place.full_name, 
                                                 tweet.vectors.df$place.country, sep=", "))
  tweet.vectors.df$user_location[is.na(tweet.vectors.df$user_location)] <- ""
  tweet.vectors.df$user_location_type <- ifelse(is.na(tweet.vectors.df$place.full_name), "User", "Place")
  tweet.vectors.df <- tweet.vectors.df[, c("created_at", "full_text", "user_screen_name", "user_verified", "user_location", "user_location_type", "sentiment")]
  
  tweet.vectors.df$full_text <- sapply(tweet.vectors.df$full_text, clean_text)
  tweet.vectors.df$user_location <- sapply(tweet.vectors.df$user_location, clean_text)
}
```

```{r, echo=FALSE}
###############################################################################
# Compute elbow and/or silhouette plot for K-means 
# on all the tweet embedding vectors
###############################################################################
if (!exists("metrics_plots") || length(metrics_plots) == 0) {
  # Generate the plot(s) if enabled
  metrics_plots <- plot_kmeans_metrics(tweet.vectors.matrix, 
                                        k_test_range=k_test_range, 
                                        seed=kmeans_clusters_seed, 
                                        max_iter=kmeans_max_iter, 
                                        nstart=kmeans_nstart,
                                        plot_elbow=compute_elbow,
                                        plot_silhouette=compute_silhouette)
}
if (exists("metrics_plots") && length(metrics_plots) > 0) {
  metrics_plots
}
```

```{r, echo=FALSE}
###############################################################################
# Run K-means on all the tweet embedding vectors
###############################################################################
if (!snapshot_loaded) {
  if (!is.na(kmeans_clusters_seed)) {
    set.seed(kmeans_clusters_seed)
  }
  km <- kmeans(tweet.vectors.matrix, centers=k, iter.max=kmeans_max_iter, nstart=kmeans_nstart)
  
  tweet.vectors.df$vector_type <- factor("tweet", levels=c("tweet", "cluster_center", "subcluster_center"))
  tweet.vectors.df$cluster <- km$cluster
  
  #append cluster centers to dataset for visualization
  centers.df <- data.frame(full_text=paste("Cluster (", rownames(km$centers), ") Center", sep=""),
                           created_at="[N/A]",
                           user_screen_name="[N/A]",
                           user_verified="[N/A]",
                           user_location="[N/A]",
                           user_location_type = "[N/A]",
                           sentiment = NA,
                           vector_type = "cluster_center",
                           cluster=as.integer(rownames(km$centers)))
  tweet.vectors.df <- rbind(tweet.vectors.df, centers.df)
  tweet.vectors.matrix <- rbind(tweet.vectors.matrix, km$centers)
}
```

```{r, echo=FALSE}
###############################################################################
# Compute elbow plot for K-means on the tweet embedding vectors in each cluster.
# Each cluster gets its own axis and all scores are normalized.
###############################################################################
if (!exists("metrics_plots2") && isTRUE(compute_elbow)) {
  # Generate the plot if enabled
  metrics_plots2 <- wssplot2(cbind(tweet.vectors.df$cluster, tweet.vectors.matrix), 
                    k_test_range=k_test_range, 
                    seed=kmeans_subclusters_seed,
                    max_iter=kmeans_max_iter, 
                    nstart=kmeans_nstart)
}
if (exists("metrics_plots2")) {
  metrics_plots2
}
```

```{r, echo=FALSE}
###############################################################################
# Run K-means again on all the tweet embedding vectors in each cluster
# to create subclusters of tweets
###############################################################################
if (!snapshot_loaded) {
  tweet.vectors.df$subcluster <- as.integer(c(0))
  
  for (i in 1:k){
   cluster.matrix <- tweet.vectors.matrix[tweet.vectors.df$cluster == i,]
   if (!is.na(kmeans_subclusters_seed)) {
     set.seed(kmeans_subclusters_seed)
   }
   cluster.km <- kmeans(cluster.matrix, centers=cluster.k, iter.max=kmeans_max_iter, nstart=kmeans_nstart)
   tweet.vectors.df[tweet.vectors.df$cluster == i, "subcluster"] <- cluster.km$cluster
   
   #append subcluster centers to dataset for visualization
   centers.df <- data.frame(full_text=paste("Subcluster (", rownames(cluster.km$centers), ") Center", sep=""),
                           created_at="[N/A]",
                           user_screen_name="[N/A]",
                           user_verified="[N/A]",
                           user_location="[N/A]",
                           user_location_type = "[N/A]",
                           sentiment = NA,
                           vector_type = "subcluster_center",
                           cluster=as.integer(i),
                           subcluster=as.integer(rownames(cluster.km$centers)))
   tweet.vectors.df <- rbind(tweet.vectors.df, centers.df)
   tweet.vectors.matrix <- rbind(tweet.vectors.matrix, cluster.km$centers)
  }
}
```

```{r, echo=FALSE}
###############################################################################
# Compute labels for each cluster and subcluster based on word frequency
# and identify the nearest neighbors to each cluster and subcluster center
###############################################################################
if (!snapshot_loaded) {
  master.word_freqs <- get_word_freqs(tweet.vectors.df$full_text)
  master.label <- get_label(master.word_freqs, top_k=master_label_top_k)
  
  clusters <- list()
  for (i in 1:k) {
    cluster.df <- tweet.vectors.df[tweet.vectors.df$cluster == i,]
    cluster.matrix <- tweet.vectors.matrix[tweet.vectors.df$cluster == i,]
      
    cluster.word_freqs <- get_word_freqs(cluster.df$full_text)
    cluster.label <- get_label(cluster.word_freqs, master.label, top_k=cluster_label_top_k)
    cluster.center <- cluster.matrix[cluster.df$vector_type=="cluster_center",]
    cluster.nearest_center <- get_nearest_center(cluster.df, cluster.matrix, cluster.center)
    
    cluster.subclusters <- list()
    for (j in 1:cluster.k) {
      subcluster.df <- cluster.df[cluster.df$subcluster == j,]
      subcluster.matrix <- cluster.matrix[cluster.df$subcluster == j,]
      
      subcluster.word_freqs <- get_word_freqs(subcluster.df$full_text)
      subcluster.label <- get_label(subcluster.word_freqs, c(master.label, cluster.label),
                                    top_k=subcluster_label_top_k)
      subcluster.center <- subcluster.matrix[subcluster.df$vector_type=="subcluster_center",]
      subcluster.nearest_center <- get_nearest_center(subcluster.df, subcluster.matrix, subcluster.center)
      
      cluster.subclusters[[j]] <- list(word_freqs=subcluster.word_freqs, label=subcluster.label, 
                                       nearest_center=subcluster.nearest_center)
    }
    
    clusters[[i]] <- list(word_freqs=cluster.word_freqs, label=cluster.label, 
                          nearest_center=cluster.nearest_center, subclusters=cluster.subclusters)
  }
}
```

```{r, echo=FALSE}
###############################################################################
# Compute cluster and subcluster summaries using 
# an abstractive summarization model (DistilBART)
###############################################################################
if (!exists("summaries.df") && isTRUE(summarize_clusters)) {
  #concatenate the nearest neighbor tweet text for each cluster & subcluster
  summaries.df <- tweet.vectors.df[tweet.vectors.df$vector_type != "tweet", 
                                   c("full_text", "vector_type", "cluster", "subcluster")]
  summaries.df$text_for_summary <- mapply(function(vector_type, cluster, subcluster) {
    if (vector_type == "cluster_center") {
      return(concat_text_for_summary(clusters[[cluster]]$nearest_center, summarize_center_nn))
    } else {
      return(concat_text_for_summary(clusters[[cluster]]$subclusters[[subcluster]]$nearest_center,
                                     summarize_center_nn))
    }
  }, summaries.df$vector_type, summaries.df$cluster, summaries.df$subcluster)
  
  #do the summarization for all clusters & subclusters in a single batch
  summaries.df$summary <- summarize(text=summaries.df$text_for_summary,
                                    max_len=summarize_max_len,
                                    num_beams=summarize_num_beams,
                                    temperature=summarize_temperature,
                                    summarizer_url=summarizer_url)
  
  #update the cluster & subcluster center vectors' text with summaries
  tweet.vectors.df[rownames(summaries.df), "full_text"] <- 
                              paste(summaries.df$full_text, ": [", summaries.df$summary, "]", sep="")
  
  #assign the summaries back to the cluster & subcluster lists
  invisible(
    mapply(function(vector_type, cluster, subcluster, summary) {
      if (vector_type == "cluster_center") {
        clusters[[cluster]]$summary <<- summary
      } else {
        clusters[[cluster]]$subclusters[[subcluster]]$summary <<- summary
      }
    }, summaries.df$vector_type, summaries.df$cluster, summaries.df$subcluster, summaries.df$summary))
}
```

```{r, echo=FALSE, fig.width=10, fig.height=6}
###############################################################################
# Run a plot showing discretized sentiment over time, for the entire sample
###############################################################################

# overall sentiment plot, line plot
if (isTRUE(show_overall_sentiment_discrete)) {
  discrete_sentiment_lines(tweet.vectors.df, sentiment_threshold)
}

```

```{r, echo=FALSE}
###############################################################################
# Run a plot showing sentiment over time, as a continuous variable, for the entire sample
###############################################################################

# overall sentiment plot, continuous
if (isTRUE(show_overall_sentiment_continuous)) {
  continuous_sentiment_barplot(tweet.vectors.df, sentiment_threshold)
}
```


```{r, echo=FALSE, fig.width=10, fig.height=10}
###############################################################################
# Compare sentiment between high-level clusters
###############################################################################

# high-level cluster sentiment plots, color gradient
if (isTRUE(show_cluster_sentiment_continuous)) {
  cluster_sentiments_plots(tweet.vectors.df, k)
}
```

```{r, echo=FALSE, fig.width=10, fig.height=10}
# high-level cluster sentiment, discrete count
if (isTRUE(show_cluster_sentiment_discrete)) {
  cluster_discrete_sentiments(tweet.vectors.df, sentiment_threshold, k)
}
```


```{r, echo=FALSE}
###############################################################################
# Run T-SNE on all the tweets and then again on each cluster to get
# plot coordinates for each tweet. We output a master plot with all clusters
# and a cluster plot with all subclusters for each cluster.
###############################################################################
run_tsne <- !snapshot_loaded || (plot_mode=="3d" && tsne_dims==2) || (plot_mode=="2d" && tsne_dims==3)
if (run_tsne) {
  tsne_dims <- ifelse(plot_mode=="3d", 3, 2)
  tsne_coords <- c("X","Y")
  if (tsne_dims == 3) {tsne_coords <- c(tsne_coords, "Z")}
  
  if (!is.na(tsne_clusters_seed)) {
     set.seed(tsne_clusters_seed)
  }
  master.tsne <- Rtsne(tweet.vectors.matrix, dims=tsne_dims, perplexity=tsne_clusters_perplexity, 
                       max_iter=tsne_clusters_max_iter, check_duplicates=FALSE)
  master.tsne.plot <- cbind(master.tsne$Y, tweet.vectors.df)
  colnames(master.tsne.plot)[1:tsne_dims] <- tsne_coords
  master.tsne.plot$full_text <- sapply(master.tsne.plot$full_text, 
                                       function(t) paste(strwrap(t ,width=60), collapse="<br>"))
  master.tsne.plot$cluster.label <- sapply(master.tsne.plot$cluster, function(c) clusters[[c]]$label)
}
taglist <- htmltools::tagList()

#Master high level plot
title <- paste("Master Plot:", master.label, "(high level clusters)")
taglist[[1]] <- plot_tweets(master.tsne.plot, title=title, sentiment_threshold=sentiment_threshold,
                            type="clusters", mode=plot_mode, webGL=TRUE)

#Cluster plots
plot_index <- 2
for (i in 1:k) {
  if (run_tsne) {
    cluster.matrix <- tweet.vectors.matrix[master.tsne.plot$cluster == i,]
    
    if (!is.na(tsne_subclusters_seed)) {
      set.seed(tsne_subclusters_seed)
    }
    cluster.tsne <- Rtsne(cluster.matrix, dims=tsne_dims, perplexity=tsne_subclusters_perplexity, 
                          max_iter=tsne_subclusters_max_iter, check_duplicates=FALSE)
    cluster.tsne.plot <- cbind(cluster.tsne$Y, master.tsne.plot[master.tsne.plot$cluster == i,])
    colnames(cluster.tsne.plot)[1:tsne_dims] <- sapply(tsne_coords, function(c) paste("cluster.", c, sep=""))
    cluster.tsne.plot$subcluster.label <- sapply(cluster.tsne.plot$subcluster, 
                                                 function(c) clusters[[i]]$subclusters[[c]]$label)
    clusters[[i]]$tsne.plot <- cluster.tsne.plot
  }
  
  #Cluster plot with original positions
  if (isTRUE(show_original_subcluster_plots)) {
    title <- paste('Cluster ', i, ": ", clusters[[i]]$label, " (as positioned in master plot)")
    taglist[[plot_index]] <- plot_tweets(clusters[[i]]$tsne.plot, title=title, 
                                         sentiment_threshold=sentiment_threshold,
                                         type="subclusters_original", mode=plot_mode, webGL=FALSE)
    plot_index <- plot_index + 1
  }
  
  #Cluster plot with regrouped positions by subcluster
  if (isTRUE(show_regrouped_subcluster_plots)) {
    title <- paste('Cluster', i, ":", clusters[[i]]$label, "(regrouped by subcluster)")
    taglist[[plot_index]] <- plot_tweets(clusters[[i]]$tsne.plot, title=title, 
                                         sentiment_threshold=sentiment_threshold,
                                         type="subclusters_regrouped", mode=plot_mode, webGL=FALSE)
    plot_index <- plot_index + 1
  }
  
  # Print cluster word frequencies
  if (isTRUE(show_word_freqs)) {
    taglist[[plot_index]] <- htmltools::HTML(kable(clusters[[i]]$word_freqs[1:5,], caption=paste("Cluster", i, "word frequencies")) %>% kable_styling())
    plot_index <- plot_index + 1
  }
  
  # Print nearest neighbors of cluster center
  if (isTRUE(show_center_nn)) {
    taglist[[plot_index]] <- htmltools::HTML(kable(clusters[[i]]$nearest_center[1:summarize_center_nn,], caption=paste("Cluster", i, "nearest neighbors to center")) %>% kable_styling())
    plot_index <- plot_index + 1
  }
  
  for (j in 1:cluster.k) {
    # Print subcluster word frequencies
    if (isTRUE(show_word_freqs)) {
      taglist[[plot_index]] <- htmltools::HTML(kable(clusters[[i]]$subclusters[[j]]$word_freqs[1:5,], caption=paste("Subcluster", j, "word frequencies")) %>% kable_styling())
      plot_index <- plot_index + 1
    }
    
    # Print nearest neighbors of subcluster center
    if (isTRUE(show_center_nn)) {
      taglist[[plot_index]] <- htmltools::HTML(kable(clusters[[i]]$subclusters[[j]]$nearest_center[1:summarize_center_nn,], caption=paste("Subcluster", j, "nearest neighbors to center")) %>% kable_styling())
      plot_index <- plot_index + 1
    }
  }
}

```

```{r, echo=FALSE}
#save snapshot if snapshot mode is 'save'
if (params$snapshot_mode == "save") {
  save.image(snapshot_filename)
}
```

\  

### Displaying `r nrow(results$df)` of `r results$total` results:

\  

```{r, echo=FALSE}
taglist
```
